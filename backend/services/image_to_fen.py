"""
Module chuy·ªÉn ·∫£nh b√†n c·ªù 3D th√†nh chu·ªói FEN s·ª≠ d·ª•ng Roboflow v√† OpenCV.
"""
import cv2
import numpy as np
from roboflow import Roboflow
import os
from dotenv import load_dotenv
import base64
import time
from datetime import datetime

try:
    from backend.services.vision_core import find_board_corners, get_board_mapping_matrix, map_point_to_grid
except ImportError:
    from vision_core import find_board_corners, get_board_mapping_matrix, map_point_to_grid

load_dotenv()

# --- C·∫§U H√åNH ---
API_KEY = os.getenv("ROBOFLOW_API_KEY")
MODEL_ID = os.getenv("ROBOFLOW_PROJECT_ID")

try:
    MODEL_VERSION = int(os.getenv("ROBOFLOW_VERSION", 1))
except:
    MODEL_VERSION = 1

CLASS_TO_FEN = {
    # Qu√¢n ƒêen
    "bp": "p", "br": "r", "bn": "n", "bb": "b", "bq": "q", "bk": "k",
    "bkn": "n", # M√£ ƒëen m·ªõi
    "black-pawn": "p", "black-rook": "r", "black-knight": "n", "black-bishop": "b", "black-queen": "q", "black-king": "k",
    "black_pawn": "p", "black_rook": "r", "black_knight": "n", "black_bishop": "b", "black_queen": "q", "black_king": "k",
    "bP": "p", "bR": "r", "bN": "n", "bB": "b", "bQ": "q", "bK": "k", "bKN": "n",

    # Qu√¢n Tr·∫Øng
    "wp": "P", "wr": "R", "wn": "N", "wb": "B", "wq": "Q", "wk": "K",
    "wkn": "N", # M√£ tr·∫Øng m·ªõi
    "white-pawn": "P", "white-rook": "R", "white-knight": "N", "white-bishop": "B", "white-queen": "Q", "white-king": "K",
    "white_pawn": "P", "white_rook": "R", "white_knight": "N", "white_bishop": "B", "white_queen": "Q", "white_king": "K",
    "wP": "P", "wR": "R", "wN": "N", "wB": "B", "wQ": "Q", "wK": "K", "wKN": "N",

    # C√°c nh√£n vi·∫øt hoa/vi·∫øt th∆∞·ªùng kh√°c
    "Pawn": "P", "Rook": "R", "Knight": "N", "Bishop": "B", "Queen": "Q", "King": "K",
    "pawn": "p", "rook": "r", "knight": "n", "bishop": "b", "queen": "q", "king": "k"
}


def analyze_image_to_fen(image_path):
    """
    H√†m ch√≠nh: Nh·∫≠n di·ªán b√†n c·ªù 3D v√† tr·∫£ v·ªÅ FEN.
    """
    print(f"--- ƒêang ph√¢n t√≠ch ·∫£nh: {image_path} ---")

    # 1. ƒê·ªçc ·∫£nh v√† Resize n·∫øu qu√° l·ªõn (Tr√°nh l·ªói 413)
    img = cv2.imread(image_path)
    if img is None:
        return None, None, "L·ªói ƒë·ªçc ·∫£nh."

    h, w = img.shape[:2]
    max_dim = 1024
    if max(h, w) > max_dim:
        scale = max_dim / max(h, w)
        new_w, new_h = int(w * scale), int(h * scale)
        img = cv2.resize(img, (new_w, new_h))
        cv2.imwrite(image_path, img)
        h, w = new_h, new_w

    # 2. G·ªçi Roboflow (AI Detect)
    try:
        if not API_KEY or not MODEL_ID:
            return None, None, "Thi·∫øu c·∫•u h√¨nh Roboflow API Key ho·∫∑c Project ID."

        rf = Roboflow(api_key=API_KEY)
        project = rf.workspace().project(MODEL_ID)
        model = project.version(MODEL_VERSION).model

        prediction = model.predict(image_path, confidence=10, overlap=30).json()
        predictions = prediction.get("predictions", [])

        if not predictions:
            print(f"‚ùå Roboflow v{MODEL_VERSION} kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£.")
            return None, None, "AI kh√¥ng t√¨m th·∫•y qu√¢n c·ªù ho·∫∑c b√†n c·ªù."
        
        # Log detected classes
        print(f" Detected: {list(set([p['class'] for p in predictions]))}")

    except Exception as e:
        print(f"‚ùå L·ªói k·∫øt n·ªëi Roboflow: {str(e)}")
        return None, None, f"L·ªói k·∫øt n·ªëi Roboflow: {str(e)}"

    # T√°ch ri√™ng qu√¢n c·ªù v√† b√†n c·ªù
    piece_preds = []
    board_box = None

    BOARD_ALIASES = ['chessboard', 'board', 'chess-board', 'chess_board', 'table']
    for p in predictions:
        cls_name = p['class'].lower()
        if any(alias in cls_name for alias in BOARD_ALIASES):
            # N·∫øu t√¨m th·∫•y nhi·ªÅu b√†n c·ªù, l·∫•y c√°i c√≥ confidence cao nh·∫•t ho·∫∑c to nh·∫•t
            if board_box is None or p['confidence'] > board_box['confidence']:
                board_box = p
        else:
            piece_preds.append(p)

    # Bi·∫øn l∆∞u t·ªça ƒë·ªô c·∫Øt (Offset)
    offset_x = 0
    offset_y = 0

    # Kh·ªüi t·∫°o c√°c bi·∫øn h√¨nh h·ªçc ƒë·ªÉ d√πng chung
    corners = None
    use_perspective = False
    M = None
    side_len = 0
    board_x1, board_y1, board_size, sq_w, sq_h = 0, 0, 0, 0, 0
    is_2d_mode = False

    if board_box:
        print(f"‚úÖ Ph√°t hi·ªán b√†n c·ªù (Confidence: {board_box['confidence']:.2f}) -> ƒêang c·∫Øt ·∫£nh...")

        # T√≠nh t·ªça ƒë·ªô c·∫Øt (Bounding Box c·ªßa class chessboard)
        bx, by = board_box['x'], board_box['y']
        bw, bh = board_box['width'], board_box['height']

        x1 = int(bx - bw / 2)
        y1 = int(by - bh / 2)
        x2 = int(bx + bw / 2)
        y2 = int(by + bh / 2)

        # --- S·ª¨A L·ªñI AN TO√ÄN (SAFE CROP) ---
        # 1. Gi·ªõi h·∫°n t·ªça ƒë·ªô trong khung h√¨nh (Clamp)
        x1 = max(0, min(x1, w - 1))
        y1 = max(0, min(y1, h - 1))
        x2 = max(x1 + 1, min(x2, w))  # ƒê·∫£m b·∫£o x2 lu√¥n l·ªõn h∆°n x1 √≠t nh·∫•t 1px
        y2 = max(y1 + 1, min(y2, h))  # ƒê·∫£m b·∫£o y2 lu√¥n l·ªõn h∆°n y1 √≠t nh·∫•t 1px

        # 2. Ki·ªÉm tra k√≠ch th∆∞·ªõc v√πng c·∫Øt h·ª£p l·ªá
        crop_w = x2 - x1
        crop_h = y2 - y1

        if crop_w > 10 and crop_h > 10:  
            try:
                # Th√™m padding 5% ƒë·ªÉ OpenCV d·ªÖ t√¨m g√≥c vi·ªÅn b√†n c·ªù h∆°n
                pad_w = int(crop_w * 0.05)
                pad_h = int(crop_h * 0.05)
                
                # T√≠nh to√°n t·ªça ƒë·ªô c·∫Øt m·ªõi c√≥ l·ªÅ
                nx1 = max(0, x1 - pad_w)
                ny1 = max(0, y1 - pad_h)
                nx2 = min(w, x2 + pad_w)
                ny2 = min(h, y2 + pad_h)

                img_crop = img[ny1:ny2, nx1:nx2]
                if img_crop.size > 0:
                    img = img_crop
                    offset_x = nx1
                    offset_y = ny1
                    h, w = img.shape[:2]

                    # --- KH·ªûI T·∫†O G√ìC T·ª™ ROBOLOW (AI) ---
                    # T√≠nh to√°n t·ªça ƒë·ªô 4 g√≥c c·ªßa b√†n c·ªù so v·ªõi ·∫£nh ƒë√£ b·ªã c·∫Øt (c√≥ padding)
                    # ƒêi·ªÅu n√†y gi√∫p ta lu√¥n c√≥ "khung x∆∞∆°ng" b√†n c·ªù k·ªÉ c·∫£ khi OpenCV th·∫•t b·∫°i
                    ai_x1 = pad_w
                    ai_y1 = pad_h
                    ai_x2 = w - pad_w
                    ai_y2 = h - pad_h
                    corners = np.array([
                        [ai_x1, ai_y1], [ai_x2, ai_y1], 
                        [ai_x2, ai_y2], [ai_x1, ai_y2]
                    ], dtype="float32")
                    use_perspective = True
                    M, side_len = get_board_mapping_matrix(corners, w, h)

                    # --- NH·∫¨N DI·ªÜN CH·∫æ ƒê·ªò 2D/SCREENSHOT ---
                    aspect_ratio = (x2 - x1) / (y2 - y1)
                    if 0.92 < aspect_ratio < 1.08 and board_box['confidence'] > 0.7:
                        print(f"üí° Ch·∫ø ƒë·ªô: B√†n c·ªù 2D/Screenshot (Aspect: {aspect_ratio:.2f}).")
                        is_2d_mode = True
                        # Kh·ª≠ l·ªÅ 2% cho 2D ƒë·ªÉ b·ªè qua nh√£n t·ªça ƒë·ªô
                        m_w, m_h = w * 0.02, h * 0.02
                        corners = np.array([
                            [m_w, m_h], [w - m_w, m_h], 
                            [w - m_w, h - m_h], [m_w, h - m_h]
                        ], dtype="float32")
                        M, side_len = get_board_mapping_matrix(corners, w, h)
                    else:
                        print(f"üí° Ch·∫ø ƒë·ªô: B√†n c·ªù 3D/·∫¢nh th·ª±c t·∫ø (Aspect: {aspect_ratio:.2f}).")
                        is_2d_mode = False

                    # D·ªãch chuy·ªÉn t·ªça ƒë·ªô qu√¢n c·ªù v·ªÅ h·ªá t·ªça ƒë·ªô ·∫£nh c·∫Øt
                    for p in piece_preds:
                        p['x'] -= offset_x
                        p['y'] -= offset_y

            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói khi c·∫Øt ·∫£nh (OpenCV): {e}. D√πng ·∫£nh g·ªëc.")
        else:
            print(f"‚ö†Ô∏è V√πng b√†n c·ªù qu√° nh·ªè ({crop_w}x{crop_h}). D√πng ·∫£nh g·ªëc.")

    else:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y class 'chessboard'. D√πng to√†n b·ªô ·∫£nh.")

    # 3. X·ª≠ l√Ω h√¨nh h·ªçc

    # --- X·ª¨ L√ù H√åNH H·ªåC (Tinh ch·ªânh g√≥c b·∫±ng OpenCV) ---
    if not is_2d_mode:
        # Th·ª≠ t√¨m g√≥c ch√≠nh x√°c h∆°n b·∫±ng OpenCV
        refined_corners = find_board_corners(img)
        
        if refined_corners is not None:
            detected_width = np.linalg.norm(refined_corners[0] - refined_corners[1])
            if detected_width > w * 0.5:
                from backend.services.vision_core import is_quad_too_distorted
                if not is_quad_too_distorted(refined_corners):
                    print("‚úÖ OpenCV tinh ch·ªânh ƒë∆∞·ª£c g√≥c b√†n c·ªù.")
                    corners = refined_corners
                    M, side_len = get_board_mapping_matrix(corners, w, h)
                else:
                    print("‚ö†Ô∏è G√≥c OpenCV qu√° m√©o, gi·ªØ nguy√™n khung AI.")
        else:
            print("‚ö†Ô∏è OpenCV kh√¥ng t√¨m th·∫•y g√≥c, s·ª≠ d·ª•ng khung b√†n c·ªù t·ª´ AI.")

    # N·∫øu ho√†n to√†n kh√¥ng c√≥ th√¥ng tin g√≥c (Tr∆∞·ªùng h·ª£p AI & OpenCV ƒë·ªÅu th·∫•t b·∫°i)
    if not use_perspective:
        if not is_2d_mode:
            print("üí° Fallback 3D: D√πng l∆∞·ªõi n·ªôi b·ªô (tr·ª´ l·ªÅ l·∫•n background).")
            # Padding 10% ƒë·ªÉ ch·∫Øc ch·∫Øn lo·∫°i b·ªè ph·∫ßn n·ªÅn g·ªó b·ªã AI b·∫Øt nh·∫ßm
            board_x1 = w * 0.1
            board_y1 = h * 0.1
            board_size = w * 0.8
            sq_w = board_size / 8
            sq_h = board_size / 8
            corners = np.array([
                [board_x1, board_y1], [board_x1 + board_size, board_y1], 
                [board_x1 + board_size, board_y1 + board_size], [board_x1, board_y1 + board_size]
            ], dtype="float32")
        else:
            print("üí° Fallback 2D: L∆∞·ªõi to√†n khung.")
            board_x1, board_y1 = 0, 0
            board_size = w
            sq_w, sq_h = w / 8, h / 8
            corners = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype="float32")

    # 4. MAPPING (S·ª≠ d·ª•ng dict ƒë·ªÉ qu·∫£n l√Ω xung ƒë·ªôt √¥ c·ªù)
    # C·∫•u tr√∫c: { (row, col): { 'char': 'P', 'conf': 0.9 } }
    occupied_squares = {}
    
    board_grid = [["1" for _ in range(8)] for _ in range(8)]
    debug_img = img.copy()

    # --- V·∫º KHUNG V√Ä L∆Ø·ªöI B√ÄN C·ªú ---
    if corners is not None:
        # 1. V·∫Ω khung b√†n c·ªù (Boundary) - M√†u xanh Neon
        cv2.polylines(debug_img, [corners.astype(int)], True, (0, 255, 0), 3)

        # 2. V·∫Ω l∆∞·ªõi 8x8
        if use_perspective and M is not None:
            try:
                M_inv = np.linalg.inv(M)
                sq_size = side_len / 8
                for i in range(1, 8): # Ch·ªâ v·∫Ω c√°c ƒë∆∞·ªùng b√™n trong (1-7)
                    # ƒê∆∞·ªùng Ngang
                    p1 = np.array([[[0, i * sq_size]]], dtype='float32')
                    p2 = np.array([[[side_len, i * sq_size]]], dtype='float32')
                    tp1 = cv2.perspectiveTransform(p1, M_inv)[0][0]
                    tp2 = cv2.perspectiveTransform(p2, M_inv)[0][0]
                    cv2.line(debug_img, tuple(tp1.astype(int)), tuple(tp2.astype(int)), (0, 255, 0), 1)
                    
                    # ƒê∆∞·ªùng D·ªçc
                    p3 = np.array([[[i * sq_size, 0]]], dtype='float32')
                    p4 = np.array([[[i * sq_size, side_len]]], dtype='float32')
                    tp3 = cv2.perspectiveTransform(p3, M_inv)[0][0]
                    tp4 = cv2.perspectiveTransform(p4, M_inv)[0][0]
                    cv2.line(debug_img, tuple(tp3.astype(int)), tuple(tp4.astype(int)), (0, 255, 0), 1)
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói khi v·∫Ω l∆∞·ªõi grid: {e}")
        elif not use_perspective:
            # Fallback grid cho tr∆∞·ªùng h·ª£p kh√¥ng c√≥ perspective
            for i in range(1, 8):
                # Ngang
                cv2.line(debug_img, (int(board_x1), int(board_y1 + i * sq_h)), 
                         (int(board_x1 + board_size), int(board_y1 + i * sq_h)), (0, 255, 0), 1)
                # D·ªçc
                cv2.line(debug_img, (int(board_x1 + i * sq_w), int(board_y1)), 
                         (int(board_x1 + i * sq_w), int(board_y1 + board_size)), (0, 255, 0), 1)

    for p in piece_preds:
        class_name = p["class"]
        conf = p.get("confidence", 0)

        # L·∫•y ƒëi·ªÉm quy chi·∫øu ƒë·ªÉ x√°c ƒë·ªãnh √¥ c·ªù
        if is_2d_mode:
            # ·∫¢nh 2D d√πng t√¢m (Center)
            ref_x = p["x"]
            ref_y = p["y"]
        else:
            # ·∫¢nh 3D d√πng ch√¢n (Bottom)
            ref_x = p["x"]
            ref_y = p["y"] + (p["height"] / 2) * 0.9 
        
        row, col = -1, -1

        if use_perspective:
            row, col = map_point_to_grid(ref_x, ref_y, M, side_len)
        else:
            rel_x = ref_x - board_x1
            rel_y = ref_y - board_y1
            col = int(rel_x // sq_w)
            row = int(rel_y // sq_h)
            row = max(0, min(7, row))
            col = max(0, min(7, col))

        # T√¨m k√Ω t·ª± FEN
        fen_char = '?'
        for k, v in CLASS_TO_FEN.items():
            if k.lower() == class_name.lower():
                fen_char = v
                break

        if fen_char != '?':
            # LOGIC X·ª¨ L√ù XUNG ƒê·ªòT √î C·ªú
            pos = (row, col)
            is_king = fen_char.lower() == 'k'
            
            should_place = False
            if pos not in occupied_squares:
                should_place = True
            else:
                existing_char = occupied_squares[pos]['char']
                existing_conf = occupied_squares[pos]['conf']
                existing_is_king = existing_char.lower() == 'k'
                
                # 1. Qu√¢n Vua c≈© lu√¥n th·∫Øng (tr·ª´ khi qu√¢n m·ªõi c≈©ng l√† vua v√† conf cao h∆°n)
                if existing_is_king and not is_king:
                    should_place = False
                # 2. Qu√¢n Vua m·ªõi th·∫Øng qu√¢n th∆∞·ªùng c≈©
                elif is_king and not existing_is_king:
                    should_place = True
                # 3. C√πng lo·∫°i (Vua-Vua ho·∫∑c Th∆∞·ªùng-Th∆∞·ªùng) -> Th·∫Øng nh·ªù Confidence
                elif conf > existing_conf:
                    should_place = True
            
            if should_place:
                occupied_squares[pos] = {'char': fen_char, 'conf': conf}
                board_grid[row][col] = fen_char
                print(f"  - Mapped {class_name} ({fen_char}) to [r:{row}, c:{col}] (Conf: {conf:.2f})")
            else:
                print(f"  - ‚ö†Ô∏è Skipped {class_name} at [r:{row}, c:{col}] - overlap with higher priority {occupied_squares[pos]['char']}")
        else:
            print(f"  - ‚ö†Ô∏è Unsupported piece class: {class_name}")

        x, y = int(p['x']), int(p['y'])
        w_p, h_p = int(p['width']), int(p['height'])

        # V·∫Ω Box ƒë·ªè
        top_left = (int(x - w_p / 2), int(y - h_p / 2))
        bottom_right = (int(x + w_p / 2), int(y + h_p / 2))
        cv2.rectangle(debug_img, top_left, bottom_right, (0, 0, 255), 2)

        # V·∫Ω t√¢m v√†ng
        cv2.circle(debug_img, (x, y), 3, (0, 255, 255), -1)

        # Th√™m nh√£n class
        cv2.putText(debug_img, class_name, (top_left[0], top_left[1] - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    # --- L∆ØU ·∫¢NH DEBUG V√ÄO FILE ---
    try:
        debug_dir = os.path.join("tests", "debug_results")
        if not os.path.exists(debug_dir):
            os.makedirs(debug_dir)
        
        # 1. L∆∞u ·∫£nh hi·ªán t·∫°i
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        debug_filename = f"debug_{timestamp}.jpg"
        debug_path = os.path.join(debug_dir, debug_filename)
        cv2.imwrite(debug_path, debug_img)
        print(f" ƒê√£ l∆∞u ·∫£nh debug: {debug_path}")

        # 2. D·ªçn d·∫πp ·∫£nh c≈© (> 24h)
        now = time.time()
        for f in os.listdir(debug_dir):
            f_path = os.path.join(debug_dir, f)
            if os.path.isfile(f_path) and now - os.path.getmtime(f_path) > 86400: # 24h
                os.remove(f_path)
                print(f" ƒê√£ x√≥a ·∫£nh debug c≈©: {f}")
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi l∆∞u/d·ªçn d·∫πp ·∫£nh debug: {e}")

        # 4. M√£ h√≥a ·∫£nh th√†nh Base64 ƒë·ªÉ g·ª≠i qua JSON
    _, buffer = cv2.imencode('.jpg', debug_img)
    debug_base64 = base64.b64encode(buffer).decode('utf-8')

    # 5. T·∫°o chu·ªói FEN cu·ªëi c√πng
    fen_rows = []
    for row in board_grid:
        empty = 0
        line = ""
        for cell in row:
            if cell == "1":
                empty += 1
            else:
                if empty > 0: line += str(empty); empty = 0
                line += cell
        if empty > 0: line += str(empty)
        fen_rows.append(line)

    final_fen = "/".join(fen_rows) + " w KQkq - 0 1"
    print(f" Final FEN: {final_fen}")

    return final_fen, debug_base64, None
