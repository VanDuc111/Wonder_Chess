"""
Module chuyá»ƒn áº£nh bÃ n cá» 3D thÃ nh chuá»—i FEN sá»­ dá»¥ng Roboflow vÃ  OpenCV.
"""
import cv2
import numpy as np
from ultralytics import YOLO
import os
from dotenv import load_dotenv
import base64
import time
from datetime import datetime

try:
    from backend.services.vision_core import find_board_corners, get_board_mapping_matrix, map_point_to_grid
except ImportError:
    from vision_core import find_board_corners, get_board_mapping_matrix, map_point_to_grid

# --- Cáº¤U HÃŒNH ---
# Tá»± Ä‘á»™ng load model má»™t láº§n duy nháº¥t
try:
    BOARD_MODEL = YOLO('backend/models/chessboard_detector_best.pt')
    PIECE_MODEL = YOLO('backend/models/chess_pieces_detector_best.pt')
    print("âœ… ÄÃ£ load thÃ nh cÃ´ng 2 model YOLO (Board & Pieces).")
except Exception as e:
    print(f"âŒ Lá»—i khi load model YOLO: {e}")
    BOARD_MODEL = None
    PIECE_MODEL = None

CLASS_TO_FEN = {
    # QuÃ¢n Äen
    "bp": "p", "br": "r", "bn": "n", "bb": "b", "bq": "q", "bk": "k",
    "bkn": "n",
    "black-pawn": "p", "black-rook": "r", "black-knight": "n", "black-bishop": "b", "black-queen": "q", "black-king": "k",
    "black_pawn": "p", "black_rook": "r", "black_knight": "n", "black_bishop": "b", "black_queen": "q", "black_king": "k",
    "bP": "p", "bR": "r", "bN": "n", "bB": "b", "bQ": "q", "bK": "k", "bKN": "n",

    # QuÃ¢n Tráº¯ng
    "wp": "P", "wr": "R", "wn": "N", "wb": "B", "wq": "Q", "wk": "K",
    "wkn": "N",
    "white-pawn": "P", "white-rook": "R", "white-knight": "N", "white-bishop": "B", "white-queen": "Q", "white-king": "K",
    "white_pawn": "P", "white_rook": "R", "white_knight": "N", "white_bishop": "B", "white_queen": "Q", "white_king": "K",
    "wP": "P", "wR": "R", "wN": "N", "wB": "B", "wQ": "Q", "wK": "K", "wKN": "N",

    # CÃ¡c nhÃ£n viáº¿t hoa/viáº¿t thÆ°á»ng khÃ¡c
    "Pawn": "P", "Rook": "R", "Knight": "N", "Bishop": "B", "Queen": "Q", "King": "K",
    "pawn": "p", "rook": "r", "knight": "n", "bishop": "b", "queen": "q", "king": "k"
}


def analyze_image_to_fen(image_path):
    """
    HÃ m chÃ­nh: Nháº­n diá»‡n bÃ n cá» 3D vÃ  tráº£ vá» FEN.
    """
    print(f"--- Äang phÃ¢n tÃ­ch áº£nh: {image_path} ---")

    # 1. Äá»c áº£nh vÃ  Resize náº¿u quÃ¡ lá»›n (TrÃ¡nh lá»—i 413)
    img = cv2.imread(image_path)
    if img is None:
        return None, None, "Lá»—i Ä‘á»c áº£nh."

    h, w = img.shape[:2] # Chiá»u cao, chiá»u rá»™ng 
    max_dim = 1024 
    if max(h, w) > max_dim:
        scale = max_dim / max(h, w)
        new_w, new_h = int(w * scale), int(h * scale)
        img = cv2.resize(img, (new_w, new_h)) # Resize áº£nh
        cv2.imwrite(image_path, img)
        h, w = new_h, new_w

    # 2. Xá»¬ LÃ AI - BÆ¯á»šC 1: TÃŒM BÃ€N Cá»œ
    board_box = None
    try:
        if BOARD_MODEL is None or PIECE_MODEL is None:
            return None, None, "Dá»‹ch vá»¥ AI chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng."

        print("- BÆ°á»›c 1: Äang tÃ¬m bÃ n cá»...")
        board_results = BOARD_MODEL.predict(image_path, conf=0.40, verbose=False)
        
        if len(board_results[0].boxes) > 0:
            # Láº¥y box cÃ³ confidence cao nháº¥t
            top_box = sorted(board_results[0].boxes, key=lambda x: x.conf[0], reverse=True)[0]
            
            # Chuyá»ƒn Ä‘á»•i format sang dict cÅ© Ä‘á»ƒ giá»¯ nguyÃªn logic xá»­ lÃ½ phÃ­a dÆ°á»›i
            x, y, w_box, h_box = top_box.xywh[0].tolist()
            board_box = {
                'x': x,
                'y': y,
                'width': w_box,
                'height': h_box,
                'confidence': float(top_box.conf[0])
            }
            print(f"âœ… ÄÃ£ tÃ¬m tháº¥y bÃ n cá» (Conf: {board_box['confidence']:.2f})")

    except Exception as e:
        print(f"âŒ Lá»—i YOLO Board Inference: {str(e)}")
        return None, None, f"Lá»—i xá»­ lÃ½ AI (Board): {str(e)}"

    # Biáº¿n lÆ°u tá»a Ä‘á»™ cáº¯t (Offset)
    offset_x = 0
    offset_y = 0

    # Khá»Ÿi táº¡o cÃ¡c biáº¿n hÃ¬nh há»c Ä‘á»ƒ dÃ¹ng chung
    corners = None
    use_perspective = False
    M = None
    side_len = 0
    board_x1, board_y1, board_size, sq_w, sq_h = 0, 0, 0, 0, 0
    is_2d_mode = False

    if board_box:
        print(f"âœ… PhÃ¡t hiá»‡n bÃ n cá» (Confidence: {board_box['confidence']:.2f}) -> Äang cáº¯t áº£nh...")

        # TÃ­nh tá»a Ä‘á»™ cáº¯t (Bounding Box cá»§a class chessboard)
        bx, by = board_box['x'], board_box['y']
        bw, bh = board_box['width'], board_box['height']

        x1 = int(bx - bw / 2)
        y1 = int(by - bh / 2)
        x2 = int(bx + bw / 2)
        y2 = int(by + bh / 2)

        # --- SAFE CROP ---
        # 1. Giá»›i háº¡n tá»a Ä‘á»™ trong khung hÃ¬nh (Clamp)
        x1 = max(0, min(x1, w - 1))
        y1 = max(0, min(y1, h - 1))
        x2 = max(x1 + 1, min(x2, w))  # Äáº£m báº£o x2 luÃ´n lá»›n hÆ¡n x1 Ã­t nháº¥t 1px
        y2 = max(y1 + 1, min(y2, h))  # Äáº£m báº£o y2 luÃ´n lá»›n hÆ¡n y1 Ã­t nháº¥t 1px

        # 2. Kiá»ƒm tra kÃ­ch thÆ°á»›c vÃ¹ng cáº¯t há»£p lá»‡
        crop_w = x2 - x1
        crop_h = y2 - y1

        if crop_w > 10 and crop_h > 10:  
            try:
                # --- PHÃN ÄOÃN NHANH 2D/3D Äá»‚ ÃP PADDING ---
                initial_aspect = crop_w / crop_h
                is_likely_2d = 0.90 < initial_aspect < 1.10 and board_box['confidence'] > 0.7
                
                # 2D chá»‰ cáº§n 2% lá» (Ä‘á»ƒ láº¥y Ä‘á»§ viá»n), 3D cáº§n 15%
                p_ratio = 0.02 if is_likely_2d else 0.15
                pad_w = int(crop_w * p_ratio)
                pad_h = int(crop_h * p_ratio)
                
                # TÃ­nh toÃ¡n tá»a Ä‘á»™ cáº¯t má»›i cÃ³ lá»
                nx1 = max(0, x1 - pad_w)
                ny1 = max(0, y1 - pad_h)
                nx2 = min(w, x2 + pad_w)
                ny2 = min(h, y2 + pad_h)

                img_crop = img[ny1:ny2, nx1:nx2]
                if img_crop.size > 0:
                    img = img_crop
                    offset_x = nx1
                    offset_y = ny1
                    h, w = img.shape[:2]

                    # --- KHá»I Táº O GÃ“C Tá»ª ROBOLOW (AI) ---
                    # TÃ­nh toÃ¡n tá»a Ä‘á»™ 4 gÃ³c cá»§a bÃ n cá» so vá»›i áº£nh Ä‘Ã£ bá»‹ cáº¯t (cÃ³ padding)
                    # Äiá»u nÃ y giÃºp ta luÃ´n cÃ³ "khung xÆ°Æ¡ng" bÃ n cá» ká»ƒ cáº£ khi OpenCV tháº¥t báº¡i
                    ai_x1 = pad_w
                    ai_y1 = pad_h
                    ai_x2 = w - pad_w
                    ai_y2 = h - pad_h
                    corners = np.array([
                        [ai_x1, ai_y1], [ai_x2, ai_y1], 
                        [ai_x2, ai_y2], [ai_x1, ai_y2]
                    ], dtype="float32")
                    use_perspective = True
                    M, side_len = get_board_mapping_matrix(corners, w, h)

                    # --- NHáº¬N DIá»†N CHáº¾ Äá»˜ 2D/3D ---
                    if is_likely_2d:
                        print(f"Cháº¿ Ä‘á»™: BÃ n cá» 2D/Screenshot (Aspect: {initial_aspect:.2f}).")
                        is_2d_mode = True
                    else:
                        print(f"Cháº¿ Ä‘á»™: BÃ n cá» 3D/áº¢nh thá»±c táº¿ (Aspect: {initial_aspect:.2f}).")
                        is_2d_mode = False

            except Exception as e:
                print(f"âš ï¸ Lá»—i khi cáº¯t áº£nh (OpenCV): {e}. DÃ¹ng áº£nh gá»‘c.")
        else:
            print(f"âš ï¸ VÃ¹ng bÃ n cá» quÃ¡ nhá» ({crop_w}x{crop_h}). DÃ¹ng áº£nh gá»‘c.")

    else:
        print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y class 'chessboard'. DÃ¹ng toÃ n bá»™ áº£nh.")

    # 4. Xá»¬ LÃ AI - BÆ¯á»šC 2: TÃŒM QUÃ‚N Cá»œ (TrÃªn áº£nh Ä‘Ã£ cáº¯t hoáº·c áº£nh gá»‘c)
    piece_preds = []
    try:
        print("- BÆ°á»›c 2: Äang nháº­n diá»‡n quÃ¢n cá»...")
        # Cháº¡y dá»± Ä‘oÃ¡n trá»±c tiáº¿p trÃªn máº£ng numpy 'img'
        piece_results = PIECE_MODEL.predict(img, conf=0.40, verbose=False)
        
        for box in piece_results[0].boxes:
            bx, by, bw, bh = box.xywh[0].tolist()
            cls_id = int(box.cls[0])
            cls_name = PIECE_MODEL.names[cls_id]
            
            piece_preds.append({
                'x': bx,
                'y': by,
                'width': bw,
                'height': bh,
                'class': cls_name,
                'confidence': float(box.conf[0])
            })
        print(f"âœ… TÃ¬m tháº¥y {len(piece_preds)} quÃ¢n cá».")
    except Exception as e:
        print(f"âŒ Lá»—i YOLO Piece Inference: {str(e)}")
        return None, None, f"Lá»—i xá»­ lÃ½ AI (Pieces): {str(e)}"

    # 5. Xá»­ lÃ½ hÃ¬nh há»c

    # --- Xá»¬ LÃ HÃŒNH Há»ŒC (Tinh chá»‰nh gÃ³c báº±ng OpenCV) ---
    if not is_2d_mode:
        # Thá»­ tÃ¬m gÃ³c chÃ­nh xÃ¡c hÆ¡n báº±ng OpenCV
        refined_corners = find_board_corners(img)
        
        if refined_corners is not None:
            detected_width = np.linalg.norm(refined_corners[0] - refined_corners[1])
            if detected_width > w * 0.5:
                from backend.services.vision_core import is_quad_too_distorted
                if not is_quad_too_distorted(refined_corners):
                    print("âœ… OpenCV tinh chá»‰nh Ä‘Æ°á»£c gÃ³c bÃ n cá».")
                    corners = refined_corners
                    M, side_len = get_board_mapping_matrix(corners, w, h)
                else:
                    print("âš ï¸ GÃ³c OpenCV quÃ¡ mÃ©o, giá»¯ nguyÃªn khung AI.")
        else:
            print("âš ï¸ OpenCV khÃ´ng tÃ¬m tháº¥y gÃ³c, sá»­ dá»¥ng khung bÃ n cá» tá»« AI.")

    # Náº¿u hoÃ n toÃ n khÃ´ng cÃ³ thÃ´ng tin gÃ³c (TrÆ°á»ng há»£p AI & OpenCV Ä‘á»u tháº¥t báº¡i)
    if not use_perspective:
        if not is_2d_mode:
            print("ğŸ’¡ Fallback 3D: DÃ¹ng lÆ°á»›i ná»™i bá»™ (trá»« lá» láº¥n background).")
            # Padding 10% Ä‘á»ƒ cháº¯c cháº¯n loáº¡i bá» pháº§n ná»n gá»— bá»‹ AI báº¯t nháº§m
            board_x1 = w * 0.1
            board_y1 = h * 0.1
            board_size = w * 0.8
            sq_w = board_size / 8
            sq_h = board_size / 8
            corners = np.array([
                [board_x1, board_y1], [board_x1 + board_size, board_y1], 
                [board_x1 + board_size, board_y1 + board_size], [board_x1, board_y1 + board_size]
            ], dtype="float32")
        else:
            print("ğŸ’¡ Fallback 2D: LÆ°á»›i toÃ n khung.")
            board_x1, board_y1 = 0, 0
            board_size = w
            sq_w, sq_h = w / 8, h / 8
            corners = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype="float32")

    # 4. MAPPING (Sá»­ dá»¥ng dict Ä‘á»ƒ quáº£n lÃ½ xung Ä‘á»™t Ã´ cá»)
    # Cáº¥u trÃºc: { (row, col): { 'char': 'P', 'conf': 0.9 } }
    occupied_squares = {}
    
    board_grid = [["1" for _ in range(8)] for _ in range(8)]
    debug_img = img.copy()

    # --- Váº¼ KHUNG VÃ€ LÆ¯á»šI BÃ€N Cá»œ ---
    if corners is not None:
        # 1. Váº½ khung bÃ n cá» (Boundary) - MÃ u xanh Neon
        cv2.polylines(debug_img, [corners.astype(int)], True, (0, 255, 0), 3)

        # 2. Váº½ lÆ°á»›i 8x8
        if use_perspective and M is not None:
            try:
                M_inv = np.linalg.inv(M)
                sq_size = side_len / 8
                for i in range(1, 8): # Chá»‰ váº½ cÃ¡c Ä‘Æ°á»ng bÃªn trong (1-7)
                    # ÄÆ°á»ng Ngang
                    p1 = np.array([[[0, i * sq_size]]], dtype='float32')
                    p2 = np.array([[[side_len, i * sq_size]]], dtype='float32')
                    tp1 = cv2.perspectiveTransform(p1, M_inv)[0][0]
                    tp2 = cv2.perspectiveTransform(p2, M_inv)[0][0]
                    cv2.line(debug_img, tuple(tp1.astype(int)), tuple(tp2.astype(int)), (0, 255, 0), 1)
                    
                    # ÄÆ°á»ng Dá»c
                    p3 = np.array([[[i * sq_size, 0]]], dtype='float32')
                    p4 = np.array([[[i * sq_size, side_len]]], dtype='float32')
                    tp3 = cv2.perspectiveTransform(p3, M_inv)[0][0]
                    tp4 = cv2.perspectiveTransform(p4, M_inv)[0][0]
                    cv2.line(debug_img, tuple(tp3.astype(int)), tuple(tp4.astype(int)), (0, 255, 0), 1)
            except Exception as e:
                print(f"âš ï¸ Lá»—i khi váº½ lÆ°á»›i grid: {e}")
        elif not use_perspective:
            # Fallback grid cho trÆ°á»ng há»£p khÃ´ng cÃ³ perspective
            for i in range(1, 8):
                # Ngang
                cv2.line(debug_img, (int(board_x1), int(board_y1 + i * sq_h)), 
                         (int(board_x1 + board_size), int(board_y1 + i * sq_h)), (0, 255, 0), 1)
                # Dá»c
                cv2.line(debug_img, (int(board_x1 + i * sq_w), int(board_y1)), 
                         (int(board_x1 + i * sq_w), int(board_y1 + board_size)), (0, 255, 0), 1)

    # --- LOGIC MAPPING VÃ€ Xá»¬ LÃ XUNG Äá»˜T QUÃ‚N Cá»œ ---
    
    # 1. Thu tháº­p táº¥t cáº£ á»©ng viÃªn há»£p lá»‡ (Mapped detections)
    mapped_detections = []
    for p in piece_preds:
        class_name = p["class"]
        conf = p.get("confidence", 0)

        # Láº¥y Ä‘iá»ƒm quy chiáº¿u (Bottom point cho 3D, Center cho 2D)
        if is_2d_mode:
            ref_x, ref_y = p["x"], p["y"]
        else:
            ref_x = p["x"]
            ref_y = p["y"] + (p["height"] / 2) * 1.05 
        
        row, col = -1, -1
        if use_perspective:
            row, col = map_point_to_grid(ref_x, ref_y, M, side_len)
        else:
            rel_x, rel_y = ref_x - board_x1, ref_y - board_y1
            col, row = int(rel_x // sq_w), int(rel_y // sq_h)
            row, col = max(0, min(7, row)), max(0, min(7, col))

        # TÃ¬m kÃ½ tá»± FEN thÃ´ng qua CLASS_TO_FEN
        fen_char = '?'
        for k, v in CLASS_TO_FEN.items():
            if k.lower() == class_name.lower():
                fen_char = v
                break

        if fen_char != '?':
            mapped_detections.append({
                'row': row, 'col': col, 
                'char': fen_char, 'conf': conf, 
                'class': class_name,
                'x': p['x'], 'y': p['y'] # Giá»¯ láº¡i tá»a Ä‘á»™ Ä‘á»ƒ váº½ debug
            })

    # 2. Quy táº¯c Sáº®T ÄÃ: Má»—i mÃ u chá»‰ cÃ³ duy nháº¥t 1 quÃ¢n Vua (King)
    # TÃ¬m kiáº¿m quÃ¢n vua cÃ³ Confidence cao nháº¥t toÃ n bÃ n cá» cho má»—i mÃ u
    best_kings = {'K': None, 'k': None}
    for det in mapped_detections:
        char = det['char']
        if char in ['K', 'k']:
            if best_kings[char] is None or det['conf'] > best_kings[char]['conf']:
                best_kings[char] = det

    # 3. Äá»• dá»¯ liá»‡u vÃ o board_grid vá»›i xá»­ lÃ½ xung Ä‘á»™t Ã´ cá»
    # Thá»© tá»± Æ°u tiÃªn: QuÃ¢n Vua lÃªn Ä‘áº§u, sau Ä‘Ã³ giáº£m dáº§n theo Confidence
    sorted_detections = sorted(mapped_detections, 
                               key=lambda x: (x['char'].lower() == 'k', x['conf']), 
                               reverse=True)

    final_placements = {} # (row, col) -> det metadata
    for det in sorted_detections:
        row, col, char, conf = det['row'], det['col'], det['char'], det['conf']
        pos = (row, col)
        
        # Bá» QUA náº¿u lÃ  quÃ¢n vua "dá»m" (Ä‘Ã£ cÃ³ quÃ¢n vua cÃ¹ng mÃ u khÃ¡c cÃ³ Conf cao hÆ¡n á»Ÿ vá»‹ trÃ­ khÃ¡c)
        if char in ['K', 'k'] and det != best_kings[char]:
            print(f"  - âš ï¸ Ignored duplicate King {char} at [r:{row}, c:{col}] (Conf: {conf:.2f})")
            continue
            
        # Xá»¬ LÃ XUNG Äá»˜T Táº I Má»˜T Ã” (Square Level Conflict)
        if pos not in final_placements:
            final_placements[pos] = det
            board_grid[row][col] = char
            print(f"  - Mapped {det['class']} ({char}) to [r:{row}, c:{col}] (Conf: {conf:.2f})")
        else:
            existing = final_placements[pos]
            # VÃ¬ ta Ä‘Ã£ sáº¯p xáº¿p Vua vÃ  Conf cao lÃªn Ä‘áº§u, cÃ¡c Ä‘á»‘ng Ä‘Ã¨ sau thÆ°á»ng lÃ  nhiá»…u
            print(f"  - âš ï¸ Overlap at [r:{row}, c:{col}]: {char} vs {existing['char']}. Kept {existing['char']}")

    # 5. Váº½ Box vÃ  nhÃ£n Debug (Váº½ dá»±a trÃªn piece_preds gá»‘c Ä‘á»ƒ Ä‘áº£m báº£o Ä‘áº§y Ä‘á»§)
    for p in piece_preds:
        class_name = p["class"]
        x, y = int(p['x']), int(p['y'])
        w_p, h_p = int(p['width']), int(p['height'])

        # Váº½ Box Ä‘á»
        top_left = (int(x - w_p / 2), int(y - h_p / 2))
        bottom_right = (int(x + w_p / 2), int(y + h_p / 2))
        cv2.rectangle(debug_img, top_left, bottom_right, (0, 0, 255), 2)

        # Váº½ tÃ¢m vÃ ng
        cv2.circle(debug_img, (x, y), 3, (0, 255, 255), -1)

        # ThÃªm nhÃ£n class
        cv2.putText(debug_img, class_name, (top_left[0], top_left[1] - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    # --- LÆ¯U áº¢NH DEBUG VÃ€O FILE ---
    try:
        debug_dir = os.path.join("tests", "debug_results")
        if not os.path.exists(debug_dir):
            os.makedirs(debug_dir)
        
        # 1. LÆ°u áº£nh hiá»‡n táº¡i
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        debug_filename = f"debug_{timestamp}.jpg"
        debug_path = os.path.join(debug_dir, debug_filename)
        cv2.imwrite(debug_path, debug_img)
        print(f" ÄÃ£ lÆ°u áº£nh debug: {debug_path}")

        # 2. Dá»n dáº¹p áº£nh cÅ© (> 24h), giá»¯ láº¡i .gitkeep
        now = time.time()
        for f in os.listdir(debug_dir):
            # Skip .gitkeep files
            if f == '.gitkeep':
                continue
            f_path = os.path.join(debug_dir, f)
            if os.path.isfile(f_path) and now - os.path.getmtime(f_path) > 86400: # 24h
                os.remove(f_path)
                print(f" ÄÃ£ xÃ³a áº£nh debug cÅ©: {f}")
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi lÆ°u/dá»n dáº¹p áº£nh debug: {e}")

        # 4. MÃ£ hÃ³a áº£nh thÃ nh Base64 Ä‘á»ƒ gá»­i qua JSON
    _, buffer = cv2.imencode('.jpg', debug_img)
    debug_base64 = base64.b64encode(buffer).decode('utf-8')

    # 5. Táº¡o chuá»—i FEN cuá»‘i cÃ¹ng
    fen_rows = []
    for row in board_grid:
        empty = 0
        line = ""
        for cell in row:
            if cell == "1":
                empty += 1
            else:
                if empty > 0: line += str(empty); empty = 0
                line += cell
        if empty > 0: line += str(empty)
        fen_rows.append(line)

    final_fen = "/".join(fen_rows) + " w KQkq - 0 1"
    print(f" Final FEN: {final_fen}")

    return final_fen, debug_base64, None
